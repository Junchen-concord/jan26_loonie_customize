import pickle
import warnings

import numpy as np
import pandas as pd
from autogluon.tabular import TabularPredictor
from scipy import stats

from config import config
from postprocess.scores.transform_score import transform_score
from postprocess.scores.xgboost_scoring import use_custom_model

warnings.filterwarnings("ignore")


def auto_gluon_prediction(
    model_input: pd.DataFrame,
    model_path: str,
    account_list: list,
    predicting_positive: bool = False,
    score_name="riskScoreV2",
    custom_model_base_url=None,
    calibrator=None,
):
    """
    Predicting any kind of scores generated by xgboost
    model_input: input feature dataframe that should contain all the relevant features
    model_path: path to the xgboost model, either a .pkl or a .json file
    account_list: list of account ids
    predicting_positive: whether the dependent measure is a positive thing, used to maintain the fact that the higher the score, the better the customer should be.
    """
    # Check if we can convert from pkl to json if it's a pkl file
    model = TabularPredictor.load(model_path, require_py_version_match=False)

    model_features = list(model.features())
    for feature in model_features:
        if feature not in model_input.columns:
            model_input.loc[:, feature] = 0
    features = model_input[model_features]

    # Use a custom model for prediction if provided
    if custom_model_base_url is not None:
        df_pred = use_custom_model(custom_model_base_url, features)
    else:
        df_pred = pd.DataFrame(model.predict_proba(features, model="CatBoost_r137_BAG_L1_FULL"))

    df_pred.columns = ["pred_0", "pred_1"]
    od = 100
    if not predicting_positive:
        df_pred[score_name] = df_pred["pred_0"].apply(lambda x: transform_score(x, od))
    else:
        df_pred[score_name] = df_pred["pred_1"].apply(lambda x: transform_score(x, od))

    if calibrator is not None:
        df_pred[score_name] = df_pred[score_name].apply(lambda x: calibrator.calibrate_score(x))
    df_pred[config.IA_ACCOUNT_ID] = account_list
    df_pred = df_pred[[config.IA_ACCOUNT_ID, score_name]]
    return df_pred


class Calibrator:
    def __init__(self, load_path):
        with open(load_path, "rb") as f:
            calibrator_data = pickle.load(f)
        self.old_scores = np.sort(calibrator_data["reference_scores"])
        self.new_scores = np.sort(calibrator_data["new_scores"])

    def calibrate_score(self, score):
        # Find the quantile of the score in the new distribution
        quantile = stats.percentileofscore(self.new_scores, score) / 100.0

        # Map to the corresponding value in the old distribution
        calibrated = np.percentile(self.old_scores, quantile * 100)
        return calibrated
